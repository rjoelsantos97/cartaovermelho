import { config } from 'dotenv';
import { resolve } from 'path';

// Load environment variables
config({ path: resolve(__dirname, '..', '.env.local') });

import { ScrapingService } from '../src/lib/scraping/scraping-service';

async function testFullScraping() {
  console.log('üöÄ Teste completo do sistema de scraping...\n');
  
  try {
    const scrapingService = new ScrapingService();
    
    console.log('üì∞ Teste 1: Teste b√°sico do scraping');
    const testResult = await scrapingService.testScraping();
    
    if (testResult.success) {
      console.log(`‚úÖ Teste bem-sucedido: ${testResult.articlesFound} artigos encontrados\n`);
    } else {
      console.log(`‚ùå Teste falhou: ${testResult.error}\n`);
      return;
    }
    
    console.log('üì∞ Teste 2: Execu√ß√£o de job de scraping completo');
    console.log('‚è≥ Iniciando job de scraping (pode demorar alguns segundos)...\n');
    
    try {
      const job = await scrapingService.runScrapingJob();
      
      console.log('üìä RESULTADOS DO JOB:');
      console.log(`   Job ID: ${job.id}`);
      console.log(`   Status: ${job.status}`);
      console.log(`   Iniciado: ${new Date(job.startedAt).toLocaleString('pt-PT')}`);
      console.log(`   Conclu√≠do: ${job.completedAt ? new Date(job.completedAt).toLocaleString('pt-PT') : 'N/A'}`);
      console.log(`   Artigos salvos: ${job.articlesScraped}`);
      
      if (job.error) {
        console.log(`   Erro: ${job.error}`);
      }
      
    } catch (jobError) {
      console.error(`‚ùå Erro no job de scraping: ${jobError}`);
    }
    
    console.log('\nüì∞ Teste 3: Verifica√ß√£o de artigos na base de dados');
    
    try {
      const recentArticles = await scrapingService.getRecentArticles(5);
      
      console.log(`‚úÖ ${recentArticles.length} artigos recentes na base de dados:`);
      
      recentArticles.forEach((article, index) => {
        console.log(`\n   ${index + 1}. ${article.title}`);
        console.log(`      Categoria: ${article.category}`);
        console.log(`      URL: ${article.source_url}`);
        console.log(`      Scraped: ${new Date(article.scraped_at).toLocaleString('pt-PT')}`);
        console.log(`      Imagem: ${article.image_url ? '‚úÖ' : '‚ùå'}`);
        console.log(`      Autor: ${article.author || 'N/A'}`);
        console.log(`      Conte√∫do: ${article.content.length} caracteres`);
      });
      
    } catch (dbError) {
      console.error(`‚ùå Erro ao verificar base de dados: ${dbError}`);
    }
    
    console.log('\nüì∞ Teste 4: Hist√≥rico de jobs');
    
    try {
      const jobs = await scrapingService.getScrapingJobs(3);
      
      console.log(`üìä ${jobs.length} jobs de scraping recentes:`);
      
      jobs.forEach((job, index) => {
        console.log(`\n   ${index + 1}. Job ${job.id.substring(0, 8)}...`);
        console.log(`      Status: ${job.status}`);
        console.log(`      Artigos: ${job.articlesScraped}`);
        console.log(`      Iniciado: ${new Date(job.startedAt).toLocaleString('pt-PT')}`);
        if (job.error) {
          console.log(`      Erro: ${job.error}`);
        }
      });
      
    } catch (jobsError) {
      console.error(`‚ùå Erro ao obter jobs: ${jobsError}`);
    }
    
    console.log('\nüéâ Teste completo do sistema de scraping conclu√≠do!');
    console.log('üí° Sistema pronto para produ√ß√£o com RSS feeds confi√°veis.');
    
  } catch (error) {
    console.error('‚ùå Erro durante teste completo:', error);
  }
}

testFullScraping();